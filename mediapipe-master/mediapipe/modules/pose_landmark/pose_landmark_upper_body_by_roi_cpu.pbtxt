# MediaPipe graph to detect/predict upper-body pose landmarks. (CPU input, and
# inference is executed on CPU.)
#
# It is required that "pose_landmark_upper_body.tflite" is available at
# "mediapipe/modules/pose_landmark/pose_landmark_upper_body.tflite"
# path during execution.
#
# EXAMPLE:
#   node {
#     calculator: "PoseLandmarkUpperBodyByRoiCpu"
#     input_stream: "IMAGE:image"
#     input_stream: "ROI:roi"
#     output_stream: "LANDMARKS:landmarks"
#   }

type: "PoseLandmarkUpperBodyByRoiCpu"

# CPU image. (ImageFrame)
input_stream: "IMAGE:image"
# ROI (region of interest) within the given image where a pose is located.
# (NormalizedRect)
input_stream: "ROI:roi"

# Pose landmarks within the given ROI. (NormalizedLandmarkList)
# We have 25 (upper-body) landmarks
# (see pose_landmark_upper_body_topology.svg), and there are other auxiliary key
# points.
# 0 - nose
# 1 - right eye (inner)
# 2 - right eye
# 3 - right eye (outer)
# 4 - left eye (inner)
# 5 - left eye
# 6 - left eye (outer)
# 7 - right ear
# 8 - left ear
# 9 - mouth (right)
# 10 - mouth (left)
# 11 - right shoulder
# 12 - left shoulder
# 13 - right elbow
# 14 - left elbow
# 15 - right wrist
# 16 - left wrist
# 17 - right pinky
# 18 - left pinky
# 19 - right index
# 20 - left index
# 21 - right thumb
# 22 - left thumb
# 23 - right hip
# 24 - left hip
#
# NOTE: if a pose is not present within the given ROI, for this particular
# timestamp there will not be an output packet in the LANDMARKS stream. However,
# the MediaPipe framework will internally inform the downstream calculators of
# the absence of this packet so that they don't wait for it unnecessarily.
output_stream: "LANDMARKS:landmarks"

# Crops the rectangle that contains a pose from the input image.
node {
  calculator: "ImageCroppingCalculator"
  input_stream: "IMAGE:image"
  input_stream: "NORM_RECT:roi"
  output_stream: "IMAGE:pose_region"
  options: {
    [mediapipe.ImageCroppingCalculatorOptions.ext] {
      border_mode: BORDER_REPLICATE
      output_max_width: 256
      output_max_height: 256
    }
  }
}

# Transforms the input image on CPU to a 256x256 image. To scale the input
# image, the scale_mode option is set to FIT to preserve the aspect ratio,
# resulting in potential letterboxing in the transformed image.
node: {
  calculator: "ImageTransformationCalculator"
  input_stream: "IMAGE:pose_region"
  output_stream: "IMAGE:transformed_pose_region"
  output_stream: "LETTERBOX_PADDING:letterbox_padding"
  options: {
    [mediapipe.ImageTransformationCalculatorOptions.ext] {
      output_width: 256
      output_height: 256
      scale_mode: FIT
    }
  }
}

# Converts the transformed input image on CPU into a tensor.
node {
  calculator: "TfLiteConverterCalculator"
  input_stream: "IMAGE:transformed_pose_region"
  output_stream: "TENSORS:input_tensors"
  options: {
    [mediapipe.TfLiteConverterCalculatorOptions.ext] {
      zero_center: false
    }
  }
}

# Runs a TensorFlow Lite model inference on CPU.
node {
  calculator: "TfLiteInferenceCalculator"
  input_stream: "TENSORS:input_tensors"
  output_stream: "TENSORS:output_tensors"
  options: {
    [mediapipe.TfLiteInferenceCalculatorOptions.ext] {
      model_path: "mediapipe/modules/pose_landmark/pose_landmark_upper_body.tflite"
      delegate { xnnpack {} }
    }
  }
}

# Splits a vector of TFLite tensors to multiple vectors according to the ranges
# specified in option.
node {
  calculator: "SplitTfLiteTensorVectorCalculator"
  input_stream: "output_tensors"
  output_stream: "landmark_tensors"
  output_stream: "pose_flag_tensor"
  options: {
    [mediapipe.SplitVectorCalculatorOptions.ext] {
      ranges: { begin: 0 end: 1 }
      ranges: { begin: 1 end: 2 }
    }
  }
}

# Converts the pose-flag tensor into a float that represents the confidence
# score of pose presence.
node {
  calculator: "TfLiteTensorsToFloatsCalculator"
  input_stream: "TENSORS:pose_flag_tensor"
  output_stream: "FLOAT:pose_presence_score"
}

# Applies a threshold to the confidence score to determine whether a pose is
# present.
node {
  calculator: "ThresholdingCalculator"
  input_stream: "FLOAT:pose_presence_score"
  output_stream: "FLAG:pose_presence"
  options: {
    [mediapipe.ThresholdingCalculatorOptions.ext] {
      threshold: 0.5
    }
  }
}

# Drop landmarks tensors if pose is not present.
node {
  calculator: "GateCalculator"
  input_stream: "landmark_tensors"
  input_stream: "ALLOW:pose_presence"
  output_stream: "ensured_landmark_tensors"
}

# Decodes the landmark tensors into a vector of lanmarks, where the landmark
# coordinates are normalized by the size of the input image to the model.
node {
  calculator: "TfLiteTensorsToLandmarksCalculator"
  input_stream: "TENSORS:ensured_landmark_tensors"
  output_stream: "NORM_LANDMARKS:raw_landmarks"
  options: {
    [mediapipe.TfLiteTensorsToLandmarksCalculatorOptions.ext] {
      num_landmarks: 31
      input_image_width: 256
      input_image_height: 256
    }
  }
}

# Adjusts landmarks (already normalized to [0.f, 1.f]) on the letterboxed pose
# image (after image transformation with the FIT scale mode) to the
# corresponding locations on the same image with the letterbox removed (pose
# image before image transformation).
node {
  calculator: "LandmarkLetterboxRemovalCalculator"
  input_stream: "LANDMARKS:raw_landmarks"
  input_stream: "LETTERBOX_PADDING:letterbox_padding"
  output_stream: "LANDMARKS:adjusted_landmarks"
}

# Projects the landmarks from the cropped pose image to the corresponding
# locations on the full image before cropping (input to the graph).
node {
  calculator: "LandmarkProjectionCalculator"
  input_stream: "NORM_LANDMARKS:adjusted_landmarks"
  input_stream: "NORM_RECT:roi"
  output_stream: "NORM_LANDMARKS:landmarks"
}
